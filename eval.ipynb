{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b64081-10bb-4ef5-a380-89b79c143ef1",
   "metadata": {},
   "source": [
    "Eval modele\n",
    "solution d'appel du retriver sur une query\n",
    "sur la base des attendu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1176b727-c87b-4171-8bc5-77efece261b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473d9a852a984a9abce7844903e5f34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daeb657f3a64236922eedd834a7fe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from rag_engine.llm_loader import load_llm\n",
    "TOK, LLM = load_llm()\n",
    "\n",
    "from pipeline import rag_pipeline, build_context, vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6b2bd8-4825-4404-b1a6-094e9945159b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Question (6ca4da60-a74c-45cb-b41c-c5fac380b7b9) : Quel est l'objectif de gestion du FCP dÃ©crit dans le document ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– RÃ©ponse LLM :\n",
      "Answer: L'objectif de gestion du FCP est, sur la durÃ©e de placement recommandÃ©e supÃ©rieure Ã  5 ans, de surperformer l'indice ICE BofA Euro Corporate (ER00 Index), en s'exposant aux marchÃ©s internationaux de taux et de crÃ©dit. Cette gestion est mise en oeuvre de faÃ§on discrÃ©tionnaire au sein de l'OPCVM. Les dÃ©cisions d'investissement intÃ¨grent Ã  la fois des critÃ¨res financiers et extra-financ\n",
      "\n",
      "âœ… RÃ©ponse attendue :\n",
      "La recherche d'une performance sur la durÃ©e de placement recommandÃ©e supÃ©rieure Ã  5 ans par un placement sur les marchÃ©s financiers actions internationales, pays Ã©mergents inclus, tout en tenant compte des enjeux de dÃ©veloppement durable.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â“ Question (0be2c984-debb-4c78-96f9-754dce277409) : Quels critÃ¨res sont pris en compte dans les dÃ©cisions d'investissement du FCP ?\n",
      "\n",
      "ðŸ¤– RÃ©ponse LLM :\n",
      "Answer: Les critÃ¨res de responsabilitÃ© environnementale, sociale et de gouvernance de l'entreprise (ESG) sont pris en compte dans les dÃ©cisions d'investissement du FCP.\n",
      "\n",
      "âœ… RÃ©ponse attendue :\n",
      "Les critÃ¨res financiers et extra-financiers, notamment les critÃ¨res de responsabilitÃ© environnementale, sociale et de gouvernance de l'entreprise (ESG).\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â“ Question (3859c017-ac8e-41bd-971f-d5d5e375b97e) : A quoi vise la prise en compte des critÃ¨res ESG dans la sÃ©lection de titres du FCP ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– RÃ©ponse LLM :\n",
      "Answer: La prise en compte des critÃ¨res ESG (Environnement, Social, Gouvernance) dans la sÃ©lection de titres du FCP vise Ã  Ã©valuer la capacitÃ© des entreprises Ã  transformer les enjeux du dÃ©veloppement durable en vecteurs de performance.\n",
      "\n",
      "âœ… RÃ©ponse attendue :\n",
      "Evaluer la capacitÃ© des entreprises Ã  transformer les enjeux du dÃ©veloppement durable en vecteurs de performance.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â“ Question (8a72a582-d7bf-44ad-84d5-fc3e4b8b8262) : Quels sont les scÃ©narios mentionnÃ©s pour un investissement utilisant un mandataire appropriÃ© ?\n",
      "\n",
      "ðŸ¤– RÃ©ponse LLM :\n",
      "Answer: ScÃ©nario favorable : entre le 31/10/2016 et le 29/10/2021. ScÃ©nario intermÃ©diaire : entre le 30/10/2015 et le 30/10/2020 ou entre le 28/02/2017 et le 28/02/2022. ScÃ©nario dÃ©favorable : entre le 31/12/2021 et le 15/1\n",
      "\n",
      "âœ… RÃ©ponse attendue :\n",
      "ScÃ©nario favorable, scÃ©nario intermÃ©diaire, scÃ©nario dÃ©favorable\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â“ Question (e943d006-d450-4c3c-897a-4ca810a92dde) : Quelles sont les dates associÃ©es Ã  chaque scÃ©nario pour un investissement utilisant un mandataire appropriÃ© ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– RÃ©ponse LLM :\n",
      "Answer: ScÃ©nario favorable : entre le 31/10/2016 et le 29/10/2021\n",
      "ScÃ©nario intermÃ©diaire : entre le 30/10/2015 et le 30/10/2020\n",
      "ScÃ©nario dÃ©favorable : entre le 31/12/2021 et le 15/12/2023\n",
      "\n",
      "âœ… RÃ©ponse attendue :\n",
      "ScÃ©nario favorable : entre le 31/10/2016 et le 29/10/2021, ScÃ©nario intermÃ©diaire : entre le 30/04/2014 et le 30/04/2019, ScÃ©nario dÃ©favorable : entre le 31/12/2021 et le 12/10/2023\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "# Fichiers dataset\n",
    "chemin_queries = \"dataset_eval/queries.json\"\n",
    "chemin_answers = \"dataset_eval/answers.json\"\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "queries = load_json(chemin_queries)\n",
    "answers = load_json(chemin_answers)\n",
    "\n",
    "# On prend les 5 premiers (clÃ©, question)\n",
    "first_five = list(islice(queries.items(), 5))\n",
    "\n",
    "for key, query in first_five:\n",
    "    print(f\"â“ Question ({key}) : {query}\\n\")\n",
    "    \n",
    "    model_answer = rag_pipeline(query)\n",
    "    \n",
    "    print(f\"ðŸ¤– RÃ©ponse LLM :\\n{model_answer}\\n\")\n",
    "    print(f\"âœ… RÃ©ponse attendue :\\n{answers[key]}\\n\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9337ce0-8421-4645-bb6a-14a88420fb02",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, query \u001b[38;5;129;01min\u001b[39;00m first_five:\n\u001b[1;32m      7\u001b[0m     answer_gt \u001b[38;5;241m=\u001b[39m answers[key]\n\u001b[0;32m----> 8\u001b[0m     answer_model \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     is_correct \u001b[38;5;241m=\u001b[39m answer_gt\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m answer_model\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     11\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(is_correct)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/pipeline.py:82\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     80\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# large pool\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# rerank dÃ©sactivÃ© par dÃ©faut pour vitesse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rerank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Construit le contexte\u001b[39;00m\n\u001b[1;32m     85\u001b[0m context \u001b[38;5;241m=\u001b[39m build_context(retrieved_docs)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36mrerank\u001b[0;34m(query, docs, use_rerank)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [(query, \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "correct = 0\n",
    "start = time.time()\n",
    "\n",
    "for key, query in first_five:\n",
    "    answer_gt = answers[key]\n",
    "    answer_model = rag_pipeline(query)\n",
    "\n",
    "    is_correct = answer_gt.lower() in answer_model.lower()\n",
    "    correct += int(is_correct)\n",
    "\n",
    "    print(f\"â“ {query}\")\n",
    "    print(f\"ðŸ¤– {answer_model}\")\n",
    "    print(f\"âœ… {answer_gt}\")\n",
    "    print(f\"ðŸŽ¯ Match: {is_correct}\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "print(f\"Temps total: {time.time()-start:.2f}s\")\n",
    "print(f\"Score: {correct}/{len(first_five)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca99c4b0-4db2-404d-99c7-0675fb52af75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  16328 MiB |  16328 MiB |  43086 MiB |  26757 MiB |\n",
      "|       from large pool |  16281 MiB |  16281 MiB |  42905 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    181 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  16328 MiB |  16328 MiB |  43086 MiB |  26757 MiB |\n",
      "|       from large pool |  16281 MiB |  16281 MiB |  42905 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    181 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  16326 MiB |  16326 MiB |  43084 MiB |  26757 MiB |\n",
      "|       from large pool |  16279 MiB |  16279 MiB |  42903 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    180 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  16468 MiB |  16468 MiB |  24566 MiB |   8098 MiB |\n",
      "|       from large pool |  16416 MiB |  16416 MiB |  24512 MiB |   8096 MiB |\n",
      "|       from small pool |     52 MiB |     52 MiB |     54 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 142478 KiB | 236732 KiB |   2769 MiB |   2630 MiB |\n",
      "|       from large pool | 138153 KiB | 234240 KiB |   2561 MiB |   2426 MiB |\n",
      "|       from small pool |   4325 KiB |   4380 KiB |    208 MiB |    204 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1517    |    1517    |    2935    |    1418    |\n",
      "|       from large pool |     587    |     587    |    1035    |     448    |\n",
      "|       from small pool |     930    |     930    |    1900    |     970    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1517    |    1517    |    2935    |    1418    |\n",
      "|       from large pool |     587    |     587    |    1035    |     448    |\n",
      "|       from small pool |     930    |     930    |    1900    |     970    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     430    |     430    |     524    |      94    |\n",
      "|       from large pool |     404    |     404    |     497    |      93    |\n",
      "|       from small pool |      26    |      26    |      27    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      94    |      94    |     779    |     685    |\n",
      "|       from large pool |      84    |      84    |     249    |     165    |\n",
      "|       from small pool |      10    |      12    |     530    |     520    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(torch.cuda.memory_summary())\n",
    "except:\n",
    "    print(\"CPU mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3096461f-94a9-491e-8565-8e8ae699f9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_answer \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/RAG-docfin/pipeline.py:82\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     80\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# large pool\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# rerank dÃ©sactivÃ© par dÃ©faut pour vitesse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rerank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Construit le contexte\u001b[39;00m\n\u001b[1;32m     85\u001b[0m context \u001b[38;5;241m=\u001b[39m build_context(retrieved_docs)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36mrerank\u001b[0;34m(query, docs, use_rerank)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [(query, \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "model_answer = rag_pipeline(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
