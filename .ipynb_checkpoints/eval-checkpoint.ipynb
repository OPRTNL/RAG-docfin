{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b64081-10bb-4ef5-a380-89b79c143ef1",
   "metadata": {},
   "source": [
    "Eval modele\n",
    "solution d'appel du retriver sur une query\n",
    "sur la base des attendu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1176b727-c87b-4171-8bc5-77efece261b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473d9a852a984a9abce7844903e5f34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daeb657f3a64236922eedd834a7fe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from rag_engine.llm_loader import load_llm\n",
    "TOK, LLM = load_llm()\n",
    "\n",
    "from pipeline import rag_pipeline, build_context, vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6b2bd8-4825-4404-b1a6-094e9945159b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ Question (6ca4da60-a74c-45cb-b41c-c5fac380b7b9) : Quel est l'objectif de gestion du FCP décrit dans le document ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Réponse LLM :\n",
      "Answer: L'objectif de gestion du FCP est, sur la durée de placement recommandée supérieure à 5 ans, de surperformer l'indice ICE BofA Euro Corporate (ER00 Index), en s'exposant aux marchés internationaux de taux et de crédit. Cette gestion est mise en oeuvre de façon discrétionnaire au sein de l'OPCVM. Les décisions d'investissement intègrent à la fois des critères financiers et extra-financ\n",
      "\n",
      "✅ Réponse attendue :\n",
      "La recherche d'une performance sur la durée de placement recommandée supérieure à 5 ans par un placement sur les marchés financiers actions internationales, pays émergents inclus, tout en tenant compte des enjeux de développement durable.\n",
      "\n",
      "────────────────────────────────────────────\n",
      "❓ Question (0be2c984-debb-4c78-96f9-754dce277409) : Quels critères sont pris en compte dans les décisions d'investissement du FCP ?\n",
      "\n",
      "🤖 Réponse LLM :\n",
      "Answer: Les critères de responsabilité environnementale, sociale et de gouvernance de l'entreprise (ESG) sont pris en compte dans les décisions d'investissement du FCP.\n",
      "\n",
      "✅ Réponse attendue :\n",
      "Les critères financiers et extra-financiers, notamment les critères de responsabilité environnementale, sociale et de gouvernance de l'entreprise (ESG).\n",
      "\n",
      "────────────────────────────────────────────\n",
      "❓ Question (3859c017-ac8e-41bd-971f-d5d5e375b97e) : A quoi vise la prise en compte des critères ESG dans la sélection de titres du FCP ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Réponse LLM :\n",
      "Answer: La prise en compte des critères ESG (Environnement, Social, Gouvernance) dans la sélection de titres du FCP vise à évaluer la capacité des entreprises à transformer les enjeux du développement durable en vecteurs de performance.\n",
      "\n",
      "✅ Réponse attendue :\n",
      "Evaluer la capacité des entreprises à transformer les enjeux du développement durable en vecteurs de performance.\n",
      "\n",
      "────────────────────────────────────────────\n",
      "❓ Question (8a72a582-d7bf-44ad-84d5-fc3e4b8b8262) : Quels sont les scénarios mentionnés pour un investissement utilisant un mandataire approprié ?\n",
      "\n",
      "🤖 Réponse LLM :\n",
      "Answer: Scénario favorable : entre le 31/10/2016 et le 29/10/2021. Scénario intermédiaire : entre le 30/10/2015 et le 30/10/2020 ou entre le 28/02/2017 et le 28/02/2022. Scénario défavorable : entre le 31/12/2021 et le 15/1\n",
      "\n",
      "✅ Réponse attendue :\n",
      "Scénario favorable, scénario intermédiaire, scénario défavorable\n",
      "\n",
      "────────────────────────────────────────────\n",
      "❓ Question (e943d006-d450-4c3c-897a-4ca810a92dde) : Quelles sont les dates associées à chaque scénario pour un investissement utilisant un mandataire approprié ?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Réponse LLM :\n",
      "Answer: Scénario favorable : entre le 31/10/2016 et le 29/10/2021\n",
      "Scénario intermédiaire : entre le 30/10/2015 et le 30/10/2020\n",
      "Scénario défavorable : entre le 31/12/2021 et le 15/12/2023\n",
      "\n",
      "✅ Réponse attendue :\n",
      "Scénario favorable : entre le 31/10/2016 et le 29/10/2021, Scénario intermédiaire : entre le 30/04/2014 et le 30/04/2019, Scénario défavorable : entre le 31/12/2021 et le 12/10/2023\n",
      "\n",
      "────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "# Fichiers dataset\n",
    "chemin_queries = \"dataset_eval/queries.json\"\n",
    "chemin_answers = \"dataset_eval/answers.json\"\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "queries = load_json(chemin_queries)\n",
    "answers = load_json(chemin_answers)\n",
    "\n",
    "# On prend les 5 premiers (clé, question)\n",
    "first_five = list(islice(queries.items(), 5))\n",
    "\n",
    "for key, query in first_five:\n",
    "    print(f\"❓ Question ({key}) : {query}\\n\")\n",
    "    \n",
    "    model_answer = rag_pipeline(query)\n",
    "    \n",
    "    print(f\"🤖 Réponse LLM :\\n{model_answer}\\n\")\n",
    "    print(f\"✅ Réponse attendue :\\n{answers[key]}\\n\")\n",
    "    print(\"────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9337ce0-8421-4645-bb6a-14a88420fb02",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, query \u001b[38;5;129;01min\u001b[39;00m first_five:\n\u001b[1;32m      7\u001b[0m     answer_gt \u001b[38;5;241m=\u001b[39m answers[key]\n\u001b[0;32m----> 8\u001b[0m     answer_model \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     is_correct \u001b[38;5;241m=\u001b[39m answer_gt\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m answer_model\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     11\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(is_correct)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/pipeline.py:82\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     80\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# large pool\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# rerank désactivé par défaut pour vitesse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rerank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Construit le contexte\u001b[39;00m\n\u001b[1;32m     85\u001b[0m context \u001b[38;5;241m=\u001b[39m build_context(retrieved_docs)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36mrerank\u001b[0;34m(query, docs, use_rerank)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [(query, \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "correct = 0\n",
    "start = time.time()\n",
    "\n",
    "for key, query in first_five:\n",
    "    answer_gt = answers[key]\n",
    "    answer_model = rag_pipeline(query)\n",
    "\n",
    "    is_correct = answer_gt.lower() in answer_model.lower()\n",
    "    correct += int(is_correct)\n",
    "\n",
    "    print(f\"❓ {query}\")\n",
    "    print(f\"🤖 {answer_model}\")\n",
    "    print(f\"✅ {answer_gt}\")\n",
    "    print(f\"🎯 Match: {is_correct}\")\n",
    "    print(\"───────────────────\")\n",
    "\n",
    "print(f\"Temps total: {time.time()-start:.2f}s\")\n",
    "print(f\"Score: {correct}/{len(first_five)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca99c4b0-4db2-404d-99c7-0675fb52af75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  16328 MiB |  16328 MiB |  43086 MiB |  26757 MiB |\n",
      "|       from large pool |  16281 MiB |  16281 MiB |  42905 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    181 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  16328 MiB |  16328 MiB |  43086 MiB |  26757 MiB |\n",
      "|       from large pool |  16281 MiB |  16281 MiB |  42905 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    181 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  16326 MiB |  16326 MiB |  43084 MiB |  26757 MiB |\n",
      "|       from large pool |  16279 MiB |  16279 MiB |  42903 MiB |  26624 MiB |\n",
      "|       from small pool |     47 MiB |     47 MiB |    180 MiB |    133 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  16468 MiB |  16468 MiB |  24566 MiB |   8098 MiB |\n",
      "|       from large pool |  16416 MiB |  16416 MiB |  24512 MiB |   8096 MiB |\n",
      "|       from small pool |     52 MiB |     52 MiB |     54 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 142478 KiB | 236732 KiB |   2769 MiB |   2630 MiB |\n",
      "|       from large pool | 138153 KiB | 234240 KiB |   2561 MiB |   2426 MiB |\n",
      "|       from small pool |   4325 KiB |   4380 KiB |    208 MiB |    204 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1517    |    1517    |    2935    |    1418    |\n",
      "|       from large pool |     587    |     587    |    1035    |     448    |\n",
      "|       from small pool |     930    |     930    |    1900    |     970    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1517    |    1517    |    2935    |    1418    |\n",
      "|       from large pool |     587    |     587    |    1035    |     448    |\n",
      "|       from small pool |     930    |     930    |    1900    |     970    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     430    |     430    |     524    |      94    |\n",
      "|       from large pool |     404    |     404    |     497    |      93    |\n",
      "|       from small pool |      26    |      26    |      27    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      94    |      94    |     779    |     685    |\n",
      "|       from large pool |      84    |      84    |     249    |     165    |\n",
      "|       from small pool |      10    |      12    |     530    |     520    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(torch.cuda.memory_summary())\n",
    "except:\n",
    "    print(\"CPU mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3096461f-94a9-491e-8565-8e8ae699f9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_answer \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/RAG-docfin/pipeline.py:82\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     80\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# large pool\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# rerank désactivé par défaut pour vitesse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rerank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Construit le contexte\u001b[39;00m\n\u001b[1;32m     85\u001b[0m context \u001b[38;5;241m=\u001b[39m build_context(retrieved_docs)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36mrerank\u001b[0;34m(query, docs, use_rerank)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/workspace/RAG-docfin/rag_engine/retriever.py:16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[1;32m     15\u001b[0m ce \u001b[38;5;241m=\u001b[39m _get_reranker()\n\u001b[0;32m---> 16\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [(query, \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mpredict(pairs)\n\u001b[1;32m     18\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "model_answer = rag_pipeline(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
